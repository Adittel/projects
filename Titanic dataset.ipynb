{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the methods used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are cleaning the data. there are rows where the data is missing.\n",
    "#in future versions we can fill in certain data points with an average\n",
    "def dataclean(file):\n",
    "    data1 = pd.read_csv(file)\n",
    "    data1 = data1.dropna(subset=('Age','Embarked','Fare',))\n",
    "    data = data1.to_numpy()\n",
    "    y= data[:,1]\n",
    "    y=y.astype('int')\n",
    "    x = data[:,[2,4,5,6,7,9,11]]\n",
    "    a,b = pd.factorize(x[:,1])\n",
    "    x[:,1]= a\n",
    "\n",
    "    a,b = pd.factorize(x[:,6])\n",
    "    x[:,6]= a\n",
    "    x.astype('float64')\n",
    "    return x , y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and predict the values\n",
    "# we are using 3 machine learning techniuqies.\n",
    "def train_pred(x, y,testing):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "    # we use k nearest neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)\n",
    "    # we use a gradient boosted classifier\n",
    "    gbc = GradientBoostingClassifier(n_estimators=20, learning_rate=.1, max_features=3, max_depth=3, random_state=1).fit(X_train, y_train)\n",
    "    # we use a support vector machine for classification.\n",
    "    svm = SVC(kernel='sigmoid').fit(X_train, y_train)\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(knn.score(X_test, y_test)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gbc.score(X_test, y_test)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(svm.score(X_test, y_test)))\n",
    "    \n",
    "    a=[[1]]\n",
    "    b=[[1]]\n",
    "    c=[[1]]\n",
    "    # run through the data and use the predict function to get a prediction for the test data.\n",
    "    # in the future we will have to input all the rows and have it disregard rows where data is missing.\n",
    "    for i in range(len(testing)):\n",
    "        n = testing[i].reshape(1,-1)\n",
    "        prediction = knn.predict(n)\n",
    "        a=np.vstack((a,prediction))\n",
    "        prediction = gbc.predict(n)\n",
    "        b=np.vstack((b,prediction))\n",
    "        prediction = svm.predict(n)\n",
    "        c=np.vstack((c,prediction))\n",
    "    a=a[1:]\n",
    "    pd.DataFrame(a, columns=[\"Survived\"]).to_csv(\"D:/chrome download/titanic/a.csv\")\n",
    "    b=b[1:]\n",
    "    pd.DataFrame(b,columns=[\"Survived\"]).to_csv(\"D:/chrome download/titanic/b.csv\")\n",
    "    c=c[1:]\n",
    "    pd.DataFrame(c,columns=[\"Survived\"]).to_csv(\"D:/chrome download/titanic/c.csv\")\n",
    "    #add more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 7)\n",
      "Accuracy score (validation): 0.685\n",
      "Accuracy score (validation): 0.792\n",
      "Accuracy score (validation): 0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train , y_train = dataclean(\"D:/chrome download/titanic/train.csv\")\n",
    "x_test, nuls = dataclean(\"D:/chrome download/titanic/test.csv\")\n",
    "print(x_test.shape)\n",
    "train_pred(x_train,y_train,x_test )\n",
    "#need to raise the scores, this is the first version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
